# chatWithPdf
This Repo demonstrates how to build a Retrieval-Augmented Generation (RAG) pipeline with LangChain, where an LLM(TheBloke/Mistral-7B-Instruct-v0.2-GGUF)  answers questions about the Apple HBR report by retrieving and grounding responses in document chunks stored in a vector database ChromaDB.  
