{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2yFgYjxL6vm"
      },
      "source": [
        "# Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Hj1OD_kkWG"
      },
      "source": [
        "## Business Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wMcRPLJKdE6"
      },
      "source": [
        "As organizations grow and scale, they are often inundated with large volumes of data, reports, and documents that contain critical information for decision-making. In real-world business settings, such as venture capital firms like Andreesen Horowitz, business analysts are required to sift through large datasets, research papers, or reports to extract relevant information that impacts strategic decisions.\n",
        "\n",
        "For instance, consider that you've just joined Andreesen Horowitz, a renowned venture capital firm, and you are tasked with analyzing a dense report like the Harvard Business Review's **\"How Apple is Organized for Innovation.\"** Going through the report manually can be extremely time-consuming as the size and complexity of these report increases. However, by using **Semantic Search** and **Retrieval-Augmented Generation (RAG)** models, you can significantly streamline this process.\n",
        "\n",
        "Imagine having the capability to directly ask questions like, “How does Apple structure its teams for innovation?” and get immediate, relevant answers drawn from the report. This ability to extract and organize specific insights quickly and accurately enables you to focus on higher-level analysis and decision-making, rather than being bogged down by information retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYKE35BRkspB"
      },
      "source": [
        "## Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcksbDgdlHhA"
      },
      "source": [
        "Develop a RAG application to help business analysts efficiently extract key insights from extensive reports, such as **How Apple is Organized for Innovation**, enabling faster and more informed decision-making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f5p5bLolH7f"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KagUxRh3lKiv"
      },
      "source": [
        "**How Apple is Organized for Innovation** - An article of 11 pages in pdf format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnwETBOE6Bz5"
      },
      "source": [
        "# Installing and Importing Necessary Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AI9r-r9WCBB4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7f4yFqLBINGG"
      },
      "outputs": [],
      "source": [
        "#Libraries for processing dataframes,text\n",
        "import json,os\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "\n",
        "#Libraries for Loading Data, Chunking, Embedding, and Vector Databases\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_O1PGdNO2M9"
      },
      "source": [
        "# Data Preparation for RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTpWESc53dL9"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ksv9hSCR4BM_"
      },
      "outputs": [],
      "source": [
        "apple_pdf_path = \"HBR_How_Apple_Is_Organized_For_Innovation-4.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jhf34I1eYNtR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_community.document_loaders.pdf.PyMuPDFLoader at 0x757f47024470>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_loader = PyMuPDFLoader(apple_pdf_path)\n",
        "pdf_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YChLS31TxC3-"
      },
      "outputs": [],
      "source": [
        "apple = pdf_loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffj0ca3eZT4u"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9weTDzMxRRS"
      },
      "source": [
        "#### Checking the first 3 pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSOv3q2pxX4z",
        "outputId": "d6b7361b-a5d5-4e5a-e308-1a7f9a425389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page Number : 1\n",
            "REPRINT R2006F\n",
            "PUBLISHED IN HBR\n",
            "NOVEMBER–DECEMBER 2020\n",
            "ARTICLE\n",
            "ORGANIZATIONAL CULTURE\n",
            "How Apple Is \n",
            "Organized  \n",
            "for Innovation\n",
            "It’s about experts leading experts. \n",
            "by Joel M. Podolny and Morten T. Hansen\n",
            "This article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.\n",
            "Page Number : 2\n",
            "2\n",
            "Harvard Business Review\n",
            "November–December 2020\n",
            "This article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.\n",
            "Page Number : 3\n",
            "PHOTOGRAPHER MIKAEL JANSSON\n",
            "How Apple Is \n",
            "Organized \n",
            "for Innovation\n",
            "It’s about experts \n",
            "leading experts.\n",
            "ORGANIZATIONAL \n",
            "CULTURE\n",
            "Joel M. \n",
            "Podolny\n",
            "Dean, Apple \n",
            "University\n",
            "Morten T. \n",
            "Hansen\n",
            "Faculty, Apple \n",
            "University\n",
            "AUTHORS\n",
            "FOR ARTICLE REPRINTS CALL 800-988-0886 OR 617-783-7500, OR VISIT HBR.ORG\n",
            "Harvard Business Review\n",
            "November–December 2020  3\n",
            "This article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    print(f\"Page Number : {i+1}\",end=\"\\n\")\n",
        "    print(apple[i].page_content,end=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIe0B8Tsx6PM"
      },
      "source": [
        "Above is the sixth page of the document.  \n",
        "- It contains shapes, text, and other elements.  \n",
        "\n",
        "Let's see how the text is extracted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "QNd6kCW3wo_t",
        "outputId": "8a3785e4-33c2-4d76-e1a0-3ea2d06e6ada"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'targets were the overriding criteria for judging investments \\nand leaders. Significantly, the bonuses of senior R&D exec-\\nutives are based on companywide performance numbers \\nrather than the costs of or revenue from particular products. \\nThus product decisions are somewhat insulated from short-\\nterm financial pressures. The finance team is not involved in \\nthe product road map meetings of engineering teams, and \\nengineering teams are not involved in pricing decisions.\\nWe don’t mean to suggest that Apple doesn’t consider \\ncosts and revenue goals when deciding which technologies \\nand features the company will pursue. It does, but in ways \\nthat differ from those employed by conventionally organized \\ncompanies. Instead of using overall cost and price targets as \\nfixed parameters within which to make design and engineer-\\ning choices, R&D leaders are expected to weigh the benefits \\nto users of those choices against cost considerations.\\nIn a functional organization, individual and team repu-\\ntations act as a control mechanism in placing bets. A case in \\npoint is the decision to introduce the dual-lens camera with \\nportrait mode in the iPhone 7 Plus in 2016. It was a big wager \\nthat the camera’s impact on users would be sufficiently great \\nto justify its significant cost.\\nOne executive told us that Paul Hubel, a senior leader \\nwho played a central role in the portrait mode effort, was \\n“out over his skis,” meaning that he and his team were taking \\na big risk: If users were unwilling to pay a premium for a \\nphone with a more costly and better camera, the team would \\nmost likely have less credibility the next time it proposed an \\nexpensive upgrade or feature. The camera turned out to be a \\ndefining feature for the iPhone 7 Plus, and its success further \\nenhanced the reputations of Hubel and his team.\\nIt’s easier to get the balance right between an attention to \\ncosts and the value added to the user experience when the \\nleaders making decisions are those with deep expertise in \\ntheir areas rather than general managers being held account-\\nable primarily for meeting numerical targets. Whereas the \\nfundamental principle of a conventional business unit struc-\\nture is to align accountability and control, the fundamental \\nprinciple of a functional organization is to align expertise and \\ndecision rights.\\nThus the link between how Apple is organized and \\nthe type of innovations it produces is clear. As Chandler \\nfamously argued, “structure follows strategy”—even though \\nApple doesn’t use the structure that he anticipated large \\nmultinationals would adopt.\\nNow let’s turn to the leadership model underlying Apple’s \\nstructure.\\nTHREE LEADERSHIP CHARACTERISTICS\\nEver since Steve Jobs implemented the functional organi-\\nzation, Apple’s managers at every level, from senior vice \\npresident on down, have been expected to possess three key \\nleadership characteristics: deep expertise that allows them \\nto meaningfully engage in all the work being done within \\ntheir individual functions; immersion in the details of those \\nfunctions; and a willingness to collaboratively debate other \\nfunctions during collective decision-making. When manag-\\ners have these attri\\xadbutes, decisions are made in a coordinated \\nfashion by the people most qualified to make them.\\nDeep expertise. Apple is not a company where general \\nmanagers oversee managers; rather, it is a company where \\nexperts lead experts. The assumption is that it’s easier to \\ntrain an expert to manage well than to train a manager to be \\nan expert. At Apple, hardware experts manage hardware, \\nsoftware experts software, and so on. (Deviations from \\nthis principle are rare.) This approach cascades down all \\nlevels of the organization through areas of ever-\\u200bincreasing \\n2019\\nDESIGN\\nOPERATIONS\\nSALES\\nHARDWARE  \\nENGINEERING\\nRETAIL\\nPEOPLE\\nSOFTWARE\\nFINANCE\\nSERVICES\\nLEGAL\\nMACHINE LEARNING & AI\\nCORPORATE COMM.\\nHARDWARE\\nSOFTWARE\\nMARKETING\\nOPERATIONS\\nSERVICES & SUPPORT\\nSALES\\nFINANCE\\nLEGAL\\nMARKETING\\nENVIRONMENT,  \\nPOLICY & SOCIAL\\nHARDWARE  \\nTECHNOLOGIES\\nMARKETING COMM.\\nCORPORATE DEV.\\nCEO\\nApple’s Functional Organization\\nIn 1997, when Steve Jobs returned to Apple, it had a conventional structure for its size and scope. It was divided into business units, each with \\nits own P&L responsibilities. After retaking the helm, Jobs put the entire company under one P&L and combined the disparate departments of \\nthe business units into one functional organization that aligns expertise with decision rights—a structure Apple retains to this day.\\nCEO\\n1998\\n6\\nHarvard Business Review\\nNovember–December 2020\\nThis article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "apple[5].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ1Ext5eyOXp"
      },
      "source": [
        "* If we observe the text closely, the text is not extracted sequentially.  \n",
        "\n",
        "* This is a limitation, as we are missing coherent text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-wNNalNxPKT"
      },
      "source": [
        "#### Checking the number of pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scMnmNKtxBea",
        "outputId": "c57a5239-8bbb-4d29-b4eb-4b25c2d7577e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(apple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECMxTH-zB-R"
      },
      "source": [
        "## Data Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uG0_pBmizGGt"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name='cl100k_base',\n",
        "    chunk_size=512,\n",
        "    chunk_overlap= 20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x757e1f12e630>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w76ji7ECzLLQ"
      },
      "outputs": [],
      "source": [
        "document_chunks = pdf_loader.load_and_split(text_splitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6TQ-mmLzR9I",
        "outputId": "52ef534a-5906-4d88-c7c3-6a45b43e6afa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(document_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "DuRoMIGNzZaJ",
        "outputId": "7db183fd-0446-4015-e24a-431df3863870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'REPRINT R2006F\\nPUBLISHED IN HBR\\nNOVEMBER–DECEMBER 2020\\nARTICLE\\nORGANIZATIONAL CULTURE\\nHow Apple Is \\nOrganized  \\nfor Innovation\\nIt’s about experts leading experts. \\nby Joel M. Podolny and Morten T. Hansen\\nThis article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_chunks[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Ju4gtXwiyILp",
        "outputId": "9e3cb84a-f296-4091-ad9b-697af730a74a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'the answer (because they don’t). This differs starkly from \\nthe way leaders question subordinates about activities in the \\nowning and teaching boxes.\\nFinally, Rosner has delegated some areas—including \\niMovie and GarageBand, in which he is not an expert—to \\npeople with the requisite capabilities. For activities in the \\ndelegating box, he assembles teams, agrees on objectives, \\nmonitors and reviews prog\\xadress, and holds the teams account-\\nable: the stuff of general management.\\nWhereas Apple’s VPs spend most of their time in the own-\\ning and learning boxes, general managers at other companies \\ntend to spend most of their time in the delegating box. Rosner \\nestimates that he spends about 40% of his time on activities \\nhe owns (including collaboration with others in a given area), \\nabout 30% on learning, about 15% on teaching, and about 15% \\non delegating. These numbers vary by manager, of course, \\ndepending on their business and the needs at a given time.\\nThe discretionary leadership model preserves the funda\\xad\\nmental principle of an effective functional organization at \\nscale—aligning expertise and decision rights. Apple can \\neffectively move into new areas when leaders like Rosner \\ntake on new responsibilities outside their original expertise, \\nand teams can grow in size when leaders teach others their \\ncraft and delegate work. We believe that Apple will continue \\nto innovate and prosper by being organized this way.\\nAPPLE’S FUNCTIONAL ORGANIZATION is rare, if not unique, \\namong very large companies. It flies in the face of prevailing \\nmanagement theory that companies should be reorganized \\ninto divisions and business units as they become large. But \\nsomething vital gets lost in a shift to business units: the \\nalignment of decision rights with expertise.\\nWhy do companies so often cling to having general man-\\nagers in charge of business units? One reason, we believe, \\nis that making the change is difficult. It entails overcoming \\ninertia, reallocating power among managers, changing an \\nindividual-\\u200boriented incentive system, and learning new ways \\nof collaborating. That is daunting when a company already \\nfaces huge external challenges. An intermediate step may be \\nto cultivate the experts-leading-experts model even within'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_chunks[-2].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "9xAQYLXqyCc6",
        "outputId": "5c684b6a-4577-4d8c-82ab-68220ab96376"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'to cultivate the experts-leading-experts model even within \\na business unit structure. For example, when filling the next \\nsenior management role, pick someone with deep expertise \\nin that area as opposed to someone who might make the best \\ngeneral manager. But a full-fledged transformation requires \\nthat leaders also transition to a functional organization. \\nApple’s track rec\\xadord proves that the rewards may justify the \\nrisks. Its approach can produce extraordinary results.\\u2002\\nHBR Reprint R2006F\\nJOEL M. PODOLNY is a vice president of Apple and the dean  \\nof Apple University. Prior to joining Apple, in 2009, he was  \\nthe dean of the Yale School of Management and on the faculty of \\nHarvard’s and Stanford’s business schools. MORTEN T. HANSEN  \\nis a member of Apple University’s faculty and a professor at the \\nUniversity of California, Berkeley. He was formerly on the faculties  \\nof Harvard Business School and INSEAD.\\nFOR ARTICLE REPRINTS CALL 800-988-0886 OR 617-783-7500, OR VISIT HBR.ORG\\nHarvard Business Review\\nNovember–December 2020 \\u200911\\nThis article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_chunks[-1].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl_9lAlGaYdf"
      },
      "source": [
        "As expected, there are some overlaps:  \n",
        "\n",
        "- The sentence '*to cultivate the experts-leading-experts model even within*' appears in both chunks.  \n",
        "- If we increase the `chunk_overlap`, the overlapping length of the sentence will also increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvHVejcWz0Bl"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "fd9e8ac5eda94d349f2b369af9b8e0fa",
            "5ba7bc5cbfad470f8b6cd2612bf1dfb5",
            "122ea0a1f2e74000b50dabd4e92a1fee",
            "c336e07f97614cf58d96ef4dba0b532f",
            "923865a7e1114b8d9440f1777c76305f",
            "071244468c4d4a61b4a8461255981b22",
            "11e70001fa8c449f978ce22afd48ea15",
            "fb7bbca2fecd456c82a14913b8b2ea9c",
            "4be290e6fe4f48e5befc6312824b7000",
            "1517054cbae045afbcac928a5b25aba2",
            "1a45aba0ef3143199da27defc7906351",
            "f19c50b81c824ce19c04e2627575c548",
            "0784683c24e34abdac58504f3b23c060",
            "9309f541ecc949dd8321175014e2432b",
            "f2e17e82dc6d46b09f7e0bb38b91d3fc",
            "6c1fbc078d2b44438f269b171840545a",
            "284dd6c6fce048db8fc3cdec0e4b3a27",
            "48f9195ed6ae44efab2f82d3ab5e9014",
            "37d513df0c4348e68ed810a56fc7be45",
            "af471519a79846c1b9a35acd0ed0f7e1",
            "db4844ce7f7a491aa20a278771bb6a53",
            "5c687094f71442348bce74578dd650bf",
            "c8c846d7ba9340a68fcbcf2c3c1c16bd",
            "a2b0165de9bb45e68c96c77ff0aa543b",
            "8b8dd0f254874f448ceb0691e5b24e13",
            "ede2d0657d7741a9a856e3ccd075d8e0",
            "5e995705a3ca4a1fbe85f7990e12498d",
            "104e907c5ac847558e30621f23bfff37",
            "6e6db55b11834d89aa72a9eed0f8641a",
            "229b642ab45248a9b5d8191c9c78b4b0",
            "c6bd713259ca4da380bc2bcb964b4bd0",
            "0b5f3adb4f1f4b5f8383297ef1b123f2",
            "00c76b11163d46e2acc9901306324d69",
            "474c5e3f171b468a91ca085c1ed42656",
            "ad33b6e9e48f479483ddf3dff54b0367",
            "3bc914a6c4104d8cae5c993a78bef7a3",
            "59951bc8ff534bb78e2801f03fafcce5",
            "b5a8e931224442b682516a7f4f5530f0",
            "96291c263adb42c4a2ddeef96eb9578a",
            "10c5f13ff2e14a1bb4fc069b3d18493b",
            "87f27fc9a4ca40448d987c15baefad18",
            "d668ec7db82d4a77bbbb2ae786116ee9",
            "9ff6a483d50e48b78a693a02bfeca462",
            "e27a06c42bd2470f80cc7a33a0db6856",
            "7dd581f9206d43b6b0fd5d841df52b19",
            "2ade54dce7a34ede9af2ce35a8e6d6cc",
            "69bb5ba5267148bd970f6c1e812f4d53",
            "1b3f9d6332914f659b2418f5c7872ff9",
            "fc9d284f48ea41e2a5118170b495be63",
            "908f92f5c8da491395eb7fd33bca91b4",
            "b04be5327ba542b69d31f62264c3b691",
            "cfcc24009c044c3384c9edb2351f9104",
            "9430a3d0b4d5446e885698e5beef8e41",
            "258c4a71fea344b995738411f1b6bbef",
            "fe1f092ee0ac4f3faff7490a00ac06b6",
            "349469e5ef7b4f60adb9721de69286c4",
            "63c6050768c3443ca009d64398db9c32",
            "3c1eac8560684f5dbcae5ba0ba2fb344",
            "e9a171c3dc6642428845867f22b5e20c",
            "28515cdb6f9049219fb72164b5da6fa9",
            "62e3f938ae9148dabd5e9c61c213dfea",
            "37151f50c7754f93b30b8dd83aa5883f",
            "7b3918214ca74f8484ce8a90385b4ded",
            "124174e5be1d487196b6c7517020af1a",
            "2a1568b7167c4aa0a5f40ead24a550aa",
            "7e6a681a18774b1cb89e4c14724ae0aa",
            "f8ad6a4bf0824915a2d0cdd1f334ad02",
            "558ed4e440934269875b734f0203d2e3",
            "3a562e80d74d4a66a19b5739e36902ee",
            "954e36502fb344bfa5d925c458f7cabd",
            "ac08a70b191948f0b32b9aa73276e7ef",
            "c92760f407854286b330e212cd716c7e",
            "ba697a1a7c0845cd96df84e982b5d1c9",
            "68b34f08c1b5485db6b361e32e1e9cc2",
            "e306e4817e0a447faa76dd87cfbbf90c",
            "8d1ec7eedefb459bb7153bfe0a3c50c5",
            "3cde06a1d3924128ad82b14c14b1800e",
            "139588481a3f47bfa1adf31dadb19c71",
            "6642f20de27d47af8ebc0c17f74301b9",
            "27c14a4b98224ed2a053297d076cd904",
            "fcaa7acf5710412d99a44f0a2977102d",
            "55815983f2154440b92a349b6636a723",
            "d8b29a3591b44946b1568c5ba9ad65a6",
            "0c67197e8a604a04843f98f6ef59e9c8",
            "bdb3a1dec16c4f78b3f67b7b7d8ec44e",
            "9c57b67ace2c4ca2afd4547f5bbb22f1",
            "4d2c37136a054141bd4a9601388c5c18",
            "a565a00855fc49bdad8e9b5bf1b688f8",
            "72b1b99b6ae5487f8e7ca6d191dceb40",
            "4794419dc53a41ceb53ef398076edbb0",
            "0328be5108064b438d127d1f3f89d706",
            "76f6ab8e8b5a4f0cafa89a5a5276f4b1",
            "4a5b7532a3cd46b389a9ba51bb877351",
            "c35efbc94c194eafb35dcf4236847de6",
            "7b28e13fb0df4cf28884af2c51c06df1",
            "a2d795f539a04bfb9713591309e85e59",
            "f4dfe2b09306405cb7acba6c80a85d76",
            "0b4f23a059f94251ae66a8bcfe098197",
            "ac8cd6eac84c4911af2de242d14f2f40",
            "db4d4e20a9f8440bb706b348cbdf94e5",
            "7cc1fc91c3b24078a41204bc6c95b62c",
            "bd7f7d5709f04c369d876038fdafb5f3",
            "85813d47137f430e8f43427746ddf447",
            "76e02cfb13444e84b607d10fc6d32599",
            "30880cb3eda9491791e6137b32eb091d",
            "4fecc2a4edd545dca5bc97d6512aaf9f",
            "1042df6a4fe54e228d0fe86708b96b41",
            "cef8b411414b4e00a179d9e8c9c28914",
            "94a6c69cbb5845eea30b5065cc95e5d3",
            "60bbb98320ee4ddbbe806180d6b24397"
          ]
        },
        "id": "c6cZVZWQz15c",
        "outputId": "9d2ae72d-543b-4a98-94c8-d2a96129e5f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10129/4198310515.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = SentenceTransformerEmbeddings(model_name='thenlper/gte-large')\n"
          ]
        }
      ],
      "source": [
        "embedding_model = SentenceTransformerEmbeddings(model_name='thenlper/gte-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dvc-CTtCz4kJ"
      },
      "outputs": [],
      "source": [
        "embedding_1 = embedding_model.embed_query(document_chunks[0].page_content)\n",
        "embedding_2 = embedding_model.embed_query(document_chunks[1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0qy6xOZ0UBe",
        "outputId": "15c425f6-7016-4f1f-af01-7118db7cb569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension of the embedding vector  1024\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Dimension of the embedding vector \",len(embedding_1))\n",
        "len(embedding_1)==len(embedding_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SRtdZdjyrXE"
      },
      "source": [
        "* The embedding model provides a fixed-length vector for any number of chunks.  \n",
        "* This is necessary because we want to compare them for similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiKCOv4X0d7B"
      },
      "source": [
        "## Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NWOqhGMV0kZ9"
      },
      "outputs": [],
      "source": [
        "out_dir = 'apple_db'\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "  os.makedirs(out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g-D3URW0iEO"
      },
      "outputs": [],
      "source": [
        "# Creates a new Chroma database\n",
        "vectorstore = Chroma.from_documents(\n",
        "    document_chunks,\n",
        "    embedding_model,\n",
        "    persist_directory=out_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x757e0a7cd5e0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuK6hsbaGfqH",
        "outputId": "32886659-2751-42fe-a194-e295229d3195"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10129/1461965951.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(persist_directory=out_dir,embedding_function=embedding_model)\n"
          ]
        }
      ],
      "source": [
        "# Loads an existing Chroma database from the directory\n",
        "vectorstore = Chroma(persist_directory=out_dir,embedding_function=embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdZON_Uj1EeS",
        "outputId": "1b1b31a0-4811-41cc-c525-3ecc6c0f1d18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
              "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              "), model_name='thenlper/gte-large', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9HgsipF1I4H",
        "outputId": "491d3ccf-cf27-4a91-895e-b3475a7ea418"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'trapped': '', 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'keywords': '', 'producer': 'Adobe PDF Library 15.0 (via http://bfo.com/products/pdf?version=2.23.5-r33279)', 'total_pages': 11, 'file_path': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'author': '', 'format': 'PDF 1.6', 'modDate': 'D:20201201183749Z', 'encryption': 'Standard V2 R3 128-bit RC4', 'page': 4, 'creationDate': \"D:20201005141842-04'00'\", 'creationdate': '2020-10-05T14:18:42-04:00', 'source': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'title': '', 'moddate': '2020-12-01T18:37:49+00:00', 'subject': ''}, page_content='WHY A FUNCTIONAL ORGANIZATION?\\nApple’s main purpose is to create products that enrich \\npeople’s daily lives. That involves not only developing \\nentirely new product categories such as the iPhone and the \\nApple Watch, but also continually innovating within those \\ncategories. Perhaps no product feature better reflects Apple’s \\ncommitment to continuous innovation than the iPhone cam-\\nera. When the iPhone was introduced, in 2007, Steve Jobs \\ndevoted only six seconds to its camera in the annual keynote \\nevent for unveiling new products. Since then iPhone camera \\ntechnology has contributed to the photography industry \\nwith a stream of innovations: High dynamic range imaging \\n(2010), panorama photos (2012), True Tone flash (2013), opti-\\ncal image stabilization (2015), the dual-lens camera (2016), \\nportrait mode (2016), portrait lighting (2017), and night mode \\n(2019) are but a few of the improvements.\\nTo create such innovations, Apple relies on a structure \\nthat centers on functional expertise. Its fundamental belief \\nis that those with the most expertise and experience in a \\ndomain should have decision rights for that domain. This \\nis based on two views: First, Apple competes in markets \\nwhere the rates of technological change and disruption are \\nhigh, so it must rely on the judgment and intuition of people \\nwith deep knowledge of the technologies responsible for \\ndisruption. Long before it can get market feedback and solid \\nmarket forecasts, the company must make bets about which \\ntechnologies and designs are likely to succeed in smart-\\nphones, computers, and so on. Relying on technical experts \\nrather than general managers increases the odds that those \\nbets will pay off.\\nSecond, Apple’s commitment to offer the best possible \\nproducts would be undercut if short-term profit and cost \\nABOUT THE ART\\nApple Park, Apple’s corporate headquarters in  \\nCupertino, California, opened in 2017.\\nMikael Jansson/Trunk Archive\\nFOR ARTICLE REPRINTS CALL 800-988-0886 OR 617-783-7500, OR VISIT HBR.ORG\\nHarvard Business Review\\nNovember–December 2020 \\u20095'),\n",
              " Document(metadata={'file_path': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'subject': '', 'producer': 'Adobe PDF Library 15.0 (via http://bfo.com/products/pdf?version=2.23.5-r33279)', 'total_pages': 11, 'trapped': '', 'source': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'author': '', 'creationDate': \"D:20201005141842-04'00'\", 'modDate': 'D:20201201183749Z', 'moddate': '2020-12-01T18:37:49+00:00', 'format': 'PDF 1.6', 'encryption': 'Standard V2 R3 128-bit RC4', 'creationdate': '2020-10-05T14:18:42-04:00', 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'keywords': '', 'title': '', 'page': 3}, page_content='WELL KNOWN FOR ITS innovations in hardware, software, \\nand services. Thanks to them, it grew from some 8,000 \\nemployees and $7\\u202fbillion in revenue in 1997, the year Steve \\nJobs returned, to 137,000 employees and $260\\u202fbillion in \\nrevenue in 2019. Much less well known are the organizational \\ndesign and the associated leadership model that have played \\na crucial role in the company’s innovation success.\\nWhen Jobs arrived back at Apple, it had a conventional \\nstructure for a company of its size and scope. It was divided \\ninto business units, each with its own P&L responsibilities. \\nGeneral managers ran the Macintosh products group, the \\ninformation appliances division, and the server products \\ndivision, among others. As is often the case with decentral-\\nized business units, managers were inclined to fight with \\none another, over transfer prices in particular. Believing that \\nconventional management had stifled innovation, Jobs, in \\nhis first year returning as CEO, laid off the general managers \\nof all the business units (in a single day), put the entire com-\\npany under one P&L, and combined the disparate functional \\ndepartments of the business units into one functional organi-\\nzation. (See the exhibit “Apple’s Functional Organization.”)\\nThe adoption of a functional structure may have been \\nun\\xadsurprising for a company of Apple’s size at the time. What is \\nsurprising—in fact, remarkable—is that Apple retains it today, \\neven though the company is nearly 40 times as large in terms \\nof revenue and far more complex than it was in 1998. Senior \\nvice presidents are in charge of functions, not products. As \\nwas the case with Jobs before him, CEO Tim Cook occupies the \\nonly position on the organizational chart where the design, \\nengineering, operations, marketing, and retail of any of Apple’s \\nmain products meet. In effect, besides the CEO, the company \\noperates with no conventional general managers: people \\nwho control an entire process from product development \\nthrough sales and are judged according to a P&L statement.\\nBusiness history and organizational theory make the case \\nthat as entrepreneurial firms grow large and complex, they'),\n",
              " Document(metadata={'format': 'PDF 1.6', 'total_pages': 11, 'page': 8, 'encryption': 'Standard V2 R3 128-bit RC4', 'author': '', 'subject': '', 'creationDate': \"D:20201005141842-04'00'\", 'title': '', 'file_path': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'source': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'creationdate': '2020-10-05T14:18:42-04:00', 'trapped': '', 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'moddate': '2020-12-01T18:37:49+00:00', 'modDate': 'D:20201201183749Z', 'keywords': '', 'producer': 'Adobe PDF Library 15.0 (via http://bfo.com/products/pdf?version=2.23.5-r33279)'}, page_content='things, that these photos often had blurring at the edges of a \\nface but sharpness on the eyes. So they charged the algorithm \\nteams with achieving the same effect. When the teams suc-\\nceeded, they knew they had an acceptable standard.\\nAnother issue that emerged was the ability to preview a \\nportrait photo with a blurred background. The camera team \\nhad designed the feature so that users could see its effect on \\ntheir photos only after they had been taken, but the human \\ninterface (HI) design team pushed back, insisting that users \\nshould be able to see a “live preview” and get some guidance \\nabout how to make adjustments before taking the photo. \\nJohnnie Manzari, a member of the HI team, gave the camera \\nteam a demo. “When we saw the demo, we realized that this \\nis what we needed to do,” Townsend told us. The members \\nof his camera hardware team weren’t sure they could do \\nit, but difficulty was not an acceptable excuse for failing to \\ndeliver what would clearly be a superior user experience. After \\nmonths of engineering effort, a key stakeholder, the video \\nengineering team (responsible for the low-level software that \\ncontrols sensor and camera operations) found a way, and the \\ncollaboration paid off. Portrait mode was central to Apple’s \\nmarketing of the iPhone 7 Plus. It proved a major reason for \\nusers’ choosing to buy and delighting in the use of the phone.\\nAs this example shows, Apple’s collaborative debate \\ninvolves people from various functions who disagree, push \\nback, promote or reject ideas, and build on one another’s \\nideas to come up with the best solutions. It requires open-\\u200b\\nmindedness from senior leaders. It also requires those \\nleaders to inspire, prod, or influence colleagues in other  \\nareas to contribute toward achieving their goals.\\nWhile Townsend is accountable for how great the camera \\nis, he needed dozens of other teams—each of which had a \\nlong list of its own commitments—to contribute their time and \\neffort to the portrait mode proj\\xadect. At Apple that’s known as \\naccountability without control: You’re accountable for making \\nthe proj\\xadect succeed even though you don’t control all the other')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.similarity_search(\"Apple Steve Jobs iPhone \",k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt3hqoXYzGoy"
      },
      "source": [
        "* From the retrieved chunks, we observe that all the chunks are related to the key terms [ 'Apple', 'Steve Jobs', 'iPhone' ]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEa5sKc41T1z"
      },
      "source": [
        "## Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zO5kmp381VsX"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type='similarity',\n",
        "    search_kwargs={'k': 2}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnKuqfWB1gBx",
        "outputId": "0452acc2-a1f2-4b34-d57e-dc03447d1738"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10129/3586710401.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  rel_docs = retriever.get_relevant_documents(\"How does does Apple develop and ship products that requires good coordination between the teams?\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'title': '', 'encryption': 'Standard V2 R3 128-bit RC4', 'modDate': 'D:20201201183749Z', 'producer': 'Adobe PDF Library 15.0 (via http://bfo.com/products/pdf?version=2.23.5-r33279)', 'trapped': '', 'creationDate': \"D:20201005141842-04'00'\", 'source': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'creationdate': '2020-10-05T14:18:42-04:00', 'format': 'PDF 1.6', 'moddate': '2020-12-01T18:37:49+00:00', 'subject': '', 'author': '', 'total_pages': 11, 'keywords': '', 'page': 7, 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'file_path': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf'}, page_content='40 specialist teams: silicon design, camera software, reliabil-\\nity engineering, motion sensor hardware, video engineering, \\ncore motion, and camera sensor design, to name just a few. \\nHow on earth does Apple develop and ship products that \\nrequire such coordination? The answer is collaborative \\ndebate. Because no function is responsible for a product or a \\nservice on its own, cross-functional collaboration is crucial.\\nWhen debates reach an impasse, as some inevitably do, \\nhigher-level managers weigh in as tiebreakers, including at \\ntimes the CEO and the senior VPs. To do this at speed with \\nsufficient attention to detail is challenging for even the best \\nof leaders, making it all the more important that the company \\nfill many senior positions from within the ranks of its VPs, \\nwho have experience in Apple’s way of operating.\\nHowever, given Apple’s size and scope, even the executive \\nteam can resolve only a limited number of stalemates. The \\nmany horizontal dependencies mean that ineffective peer \\nrelationships at the VP and director levels have the potential \\nto undermine not only particular proj\\xadects but the entire \\ncompany. Consequently, for people to attain and remain in \\na leadership position within a function, they must be highly \\neffective collaborators.\\nThat doesn’t mean people can’t express their points of \\nview. Leaders are expected to hold strong, well-grounded \\nviews and advocate forcefully for them, yet also be willing  \\nto change their minds when presented with evidence \\nthat others’ views are better. Doing so is not always \\neasy, of course. A leader’s ability to be both partisan and \\nopen-minded is facilitated by two things: deep understand-\\ning of and devotion to the company’s values and common \\npurpose, and a commitment to separating how right from \\nhow hard a particular path is so that the difficulty of execut-\\ning a decision doesn’t prevent its being selected.\\nThe development of the iPhone’s portrait mode illustrates \\na fanatical attention to detail at the leadership level, intense \\ncollaborative debate among teams, and the power of a shared \\npurpose to shape and ultimately resolve debates. In 2009 \\nHubel had the idea of developing an iPhone feature that \\nwould allow people to take portrait photos with bokeh—'),\n",
              " Document(metadata={'creationDate': \"D:20201005141842-04'00'\", 'title': '', 'keywords': '', 'trapped': '', 'total_pages': 11, 'creationdate': '2020-10-05T14:18:42-04:00', 'source': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'page': 6, 'creator': 'Adobe InDesign 14.0 (Macintosh)', 'format': 'PDF 1.6', 'subject': '', 'author': '', 'file_path': 'HBR_How_Apple_Is_Organized_For_Innovation-4.pdf', 'producer': 'Adobe PDF Library 15.0 (via http://bfo.com/products/pdf?version=2.23.5-r33279)', 'modDate': 'D:20201201183749Z', 'moddate': '2020-12-01T18:37:49+00:00', 'encryption': 'Standard V2 R3 128-bit RC4'}, page_content='Apple is run. Leaders can push, probe, and “smell” an issue. \\nThey know which details are important and where to focus \\ntheir attention. Many people at Apple see it as liberating, \\neven exhilarating, to work for experts, who provide better \\nguidance and mentoring than a general manager would. \\nTogether, all can strive to do the best work of their lives in \\ntheir chosen area.\\nWillingness to collaboratively debate. Apple has \\nhundreds of specialist teams across the company, dozens of \\nwhich may be needed for even one key component of a new \\nproduct offering. For example, the dual-lens camera with \\nportrait mode required the collaboration of no fewer than  \\nApple leaders are expected to possess deep expertise, be immersed \\nin the details of their functions, and engage in collaborative debate.\\nORGANIZATIONAL \\nCULTURE\\nFOR ARTICLE REPRINTS CALL 800-988-0886 OR 617-783-7500, OR VISIT HBR.ORG\\nHarvard Business Review\\nNovember–December 2020 \\u20097\\nThis article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.')]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rel_docs = retriever.get_relevant_documents(\"How does does Apple develop and ship products that requires good coordination between the teams?\")\n",
        "rel_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'40 specialist teams: silicon design, camera software, reliabil-\\nity engineering, motion sensor hardware, video engineering, \\ncore motion, and camera sensor design, to name just a few. \\nHow on earth does Apple develop and ship products that \\nrequire such coordination? The answer is collaborative \\ndebate. Because no function is responsible for a product or a \\nservice on its own, cross-functional collaboration is crucial.\\nWhen debates reach an impasse, as some inevitably do, \\nhigher-level managers weigh in as tiebreakers, including at \\ntimes the CEO and the senior VPs. To do this at speed with \\nsufficient attention to detail is challenging for even the best \\nof leaders, making it all the more important that the company \\nfill many senior positions from within the ranks of its VPs, \\nwho have experience in Apple’s way of operating.\\nHowever, given Apple’s size and scope, even the executive \\nteam can resolve only a limited number of stalemates. The \\nmany horizontal dependencies mean that ineffective peer \\nrelationships at the VP and director levels have the potential \\nto undermine not only particular proj\\xadects but the entire \\ncompany. Consequently, for people to attain and remain in \\na leadership position within a function, they must be highly \\neffective collaborators.\\nThat doesn’t mean people can’t express their points of \\nview. Leaders are expected to hold strong, well-grounded \\nviews and advocate forcefully for them, yet also be willing  \\nto change their minds when presented with evidence \\nthat others’ views are better. Doing so is not always \\neasy, of course. A leader’s ability to be both partisan and \\nopen-minded is facilitated by two things: deep understand-\\ning of and devotion to the company’s values and common \\npurpose, and a commitment to separating how right from \\nhow hard a particular path is so that the difficulty of execut-\\ning a decision doesn’t prevent its being selected.\\nThe development of the iPhone’s portrait mode illustrates \\na fanatical attention to detail at the leadership level, intense \\ncollaborative debate among teams, and the power of a shared \\npurpose to shape and ultimately resolve debates. In 2009 \\nHubel had the idea of developing an iPhone feature that \\nwould allow people to take portrait photos with bokeh—'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rel_docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Apple is run. Leaders can push, probe, and “smell” an issue. \\nThey know which details are important and where to focus \\ntheir attention. Many people at Apple see it as liberating, \\neven exhilarating, to work for experts, who provide better \\nguidance and mentoring than a general manager would. \\nTogether, all can strive to do the best work of their lives in \\ntheir chosen area.\\nWillingness to collaboratively debate. Apple has \\nhundreds of specialist teams across the company, dozens of \\nwhich may be needed for even one key component of a new \\nproduct offering. For example, the dual-lens camera with \\nportrait mode required the collaboration of no fewer than  \\nApple leaders are expected to possess deep expertise, be immersed \\nin the details of their functions, and engage in collaborative debate.\\nORGANIZATIONAL \\nCULTURE\\nFOR ARTICLE REPRINTS CALL 800-988-0886 OR 617-783-7500, OR VISIT HBR.ORG\\nHarvard Business Review\\nNovember–December 2020 \\u20097\\nThis article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rel_docs[1].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkYpfpUAzbqK"
      },
      "source": [
        "- We can observe that the two relevant chunks contain the answer to the query.  \n",
        "- If we increase the **`k`** value, there is a chance that we might find the answer in even more chunks.  \n",
        "- This is a hyperparameter that we need to tune to get the best context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imCgFJyq2SA6"
      },
      "source": [
        "# Defining the Response Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVdPdgVL9fhk"
      },
      "source": [
        "## Downloading and Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded to: /home/dell/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "local_path = hf_hub_download(\n",
        "    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n",
        "    filename=\"mistral-7b-instruct-v0.2.Q6_K.gguf\"\n",
        ")\n",
        "\n",
        "print(\"Downloaded to:\", local_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46dB9ZqQ9fhl",
        "outputId": "e7f016bf-d28c-4e77-e790-3b5a19a4bf32"
      },
      "outputs": [],
      "source": [
        "#uncomment the below snippet of code if the runtime is connected to GPU.\n",
        "# llm = Llama(\n",
        "#     model_path=local_path,\n",
        "#     n_ctx=5000,\n",
        "#     n_gpu_layers=38,\n",
        "#     n_batch=512\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9FjKutIA9fhl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /home/dell/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q6_K\n",
            "print_info: file size   = 5.53 GiB (6.56 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: printing all EOG tokens:\n",
            "load:   - 2 ('</s>')\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1637 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 32768\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: is_swa_any       = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 1000000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 32768\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 7.24 B\n",
            "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: PAD token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q6_K) (and 290 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  5666.09 MiB\n",
            "...................................................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 1024\n",
            "llama_context: n_ctx_per_seq = 1024\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 1000000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (1024) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.12 MiB\n",
            "create_memory: n_ctx = 1024 (padded)\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   128.00 MiB\n",
            "llama_kv_cache_unified: size =  128.00 MiB (  1024 cells,  32 layers,  1/1 seqs), K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 2328\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:        CPU compute buffer size =   114.01 MiB\n",
            "llama_context: graph nodes  = 1126\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        }
      ],
      "source": [
        "#uncomment the below snippet of code if the runtime is connected to CPU only.\n",
        "llm = Llama(\n",
        "   model_path=local_path,\n",
        "   n_ctx=1024,\n",
        "   n_cores=-2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /home/dell/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q6_K\n",
            "print_info: file size   = 5.53 GiB (6.56 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: printing all EOG tokens:\n",
            "load:   - 2 ('</s>')\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1637 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 32768\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: is_swa_any       = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 1000000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 32768\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 7.24 B\n",
            "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: PAD token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q6_K) (and 290 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  5666.09 MiB\n",
            "...................................................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 4096\n",
            "llama_context: n_ctx_per_seq = 4096\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 1000000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.12 MiB\n",
            "create_memory: n_ctx = 4096 (padded)\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   512.00 MiB\n",
            "llama_kv_cache_unified: size =  512.00 MiB (  4096 cells,  32 layers,  1/1 seqs), K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 2328\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:        CPU compute buffer size =   300.01 MiB\n",
            "llama_context: graph nodes  = 1126\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        }
      ],
      "source": [
        "llm = Llama(\n",
        "    model_path=local_path,\n",
        "    n_ctx=4096,\n",
        "    n_threads=max(1, os.cpu_count() - 2)  # leaves 2 cores free\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "JGuUFLSXvOSt",
        "outputId": "6fe263d4-892d-4444-dae3-ed8f00941b1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    1145.35 ms\n",
            "llama_perf_context_print: prompt eval time =    1145.24 ms /    17 tokens (   67.37 ms per token,    14.84 tokens per second)\n",
            "llama_perf_context_print:        eval time =    3625.31 ms /    15 runs   (  241.69 ms per token,     4.14 tokens per second)\n",
            "llama_perf_context_print:       total time =    4774.86 ms /    32 tokens\n",
            "llama_perf_context_print:    graphs reused =         14\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' The answer is Agile Development and Scrum methodology.\\n\\nIn this'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(\"How does Apple develop and ship products that requires good coordination between the teams?\")['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnasHS43vaBD"
      },
      "source": [
        "- The response seems generic and appears to be derived from another article. Let's provide our own context and align the response with our needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw8qcwq66B0C",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## System and User Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRkZYtO6B0D"
      },
      "source": [
        "Prompts guide the model to generate accurate responses. Here, we define two parts:\n",
        "\n",
        "    1. The system message describing the assistant's role.\n",
        "    2. A user message template including context and the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1737358838889
        },
        "id": "Dyl60SEs6B0D",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "qna_system_message = \"\"\"\n",
        "You are an assistant whose work is to review the report and provide the appropriate answers from the context.\n",
        "User input will have the context required by you to answer user questions.\n",
        "This context will begin with the token: ###Context.\n",
        "The context contains references to specific portions of a document relevant to the user query.\n",
        "\n",
        "User questions will begin with the token: ###Question.\n",
        "\n",
        "Please answer only using the context provided in the input. Do not mention anything about the context in your final answer.\n",
        "\n",
        "If the answer is not found in the context, respond \"I don't know\".\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XW38rWoNjJkQ"
      },
      "outputs": [],
      "source": [
        "qna_user_message_template = \"\"\"\n",
        "###Context\n",
        "Here are some documents that are relevant to the question mentioned below.\n",
        "{context}\n",
        "\n",
        "###Question\n",
        "{question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkIteX4m6mny"
      },
      "source": [
        "## Response Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "J-SfCZqC6B0E",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_rag_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=k)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "\n",
        "    # Combine document chunks into a single context\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    user_message = qna_user_message_template.replace('{context}', context_for_query)\n",
        "    user_message = user_message.replace('{question}', user_input)\n",
        "\n",
        "    prompt = qna_system_message + '\\n' + user_message\n",
        "\n",
        "    # Generate the response\n",
        "    try:\n",
        "        response = llm(\n",
        "                  prompt=prompt,\n",
        "                  max_tokens=max_tokens,\n",
        "                  temperature=temperature,\n",
        "                  top_p=top_p,\n",
        "                  top_k=top_k\n",
        "                  )\n",
        "\n",
        "        # Extract and print the model's response\n",
        "        response = response['choices'][0]['text'].strip()\n",
        "    except Exception as e:\n",
        "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffP1SRYbPQHN"
      },
      "source": [
        "# Question Answering using RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjajBEj06B0E"
      },
      "source": [
        "### Query 1: Who are the authors of this article and who published this article ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt4TAQNa6B0E",
        "outputId": "09585035-334f-4f10-92ec-d2ed52bc18e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n",
            "Morten T. Hansen and Joel M. Podolny authored this article and Harvard Business Review published it.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "print(generate_rag_response(user_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 452 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1175.68 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =    8648.28 ms /    35 runs   (  247.09 ms per token,     4.05 tokens per second)\n",
            "llama_perf_context_print:       total time =    8659.14 ms /    36 tokens\n",
            "llama_perf_context_print:    graphs reused =         33\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n",
            "The authors of the article are Joel M. Podolny and Morten T. Hansen. The article was published by Harvard Business Review.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "print(generate_rag_response(user_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYAgvE7700Gx"
      },
      "source": [
        "- The answer is clear, concise, and focused, without any unnecessary information.  \n",
        "\n",
        "- For queries like this, we expect a response of this nature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDw8zXuq6B0F"
      },
      "source": [
        "### Query 2: List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "i92cv0dQ6B0F",
        "outputId": "86958a08-1c4f-4ee3-9d3b-aa2fa2e91b29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 145 prefix-match hit, remaining 1694 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1175.68 ms\n",
            "llama_perf_context_print: prompt eval time =  138605.39 ms /  1694 tokens (   81.82 ms per token,    12.22 tokens per second)\n",
            "llama_perf_context_print:        eval time =   22069.16 ms /    81 runs   (  272.46 ms per token,     3.67 tokens per second)\n",
            "llama_perf_context_print:       total time =  160704.59 ms /  1775 tokens\n",
            "llama_perf_context_print:    graphs reused =         78\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"- Deep expertise\\n  * Apple is a company where experts lead experts.\\n  * The assumption is that it's easier to train an expert to manage well than to train a manager to be an expert.\\n\\n- Immersion in the details\\n  * Leaders should know the details of their organization three levels down.\\n  * This demands extreme precision in manufacturing and production processes.\""
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
        "generate_rag_response(user_input_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe-GwPNs1XDC"
      },
      "source": [
        "- The response contains only two leadership characteristics, but they are well explained.  \n",
        "- Perhaps if we increase the **`max_tokens`**, we might get the third characteristic as well (assuming it is in the document)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TggYyQPL6B0G"
      },
      "source": [
        "### Query 3: Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Ed6x6LGb6B0G",
        "outputId": "1d0aaa84-9c13-403a-ce78-94006630f174"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I don't know. The context does mention that Apple's functional organization and leadership model have played a crucial role in the company's innovation success, but it doesn't provide specific examples of how this has manifested in successful innovations.\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
        "generate_rag_response(user_input_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSQzbaha1xvJ"
      },
      "source": [
        "- If we look at the system prompt, we explicitly mentioned that the query should not be answered if it cannot be derived from the context.  \n",
        "\n",
        "- As expected, the model has done its job well. It has eliminated hallucination."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7TYrqycEITB"
      },
      "source": [
        "## Fine-tuning Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tt270LOmj3t"
      },
      "source": [
        "### Query 1: Who are the authors of this article and who published this article ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qqdrbBN1mj3t",
        "outputId": "d0bb2842-b5f1-44c7-a3f1-92b0ca8d4af9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Answer:\\nMorten T. Hansen and Joel M. Podolny authored this article and Harvard Business Review published it.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "generate_rag_response(user_input, max_tokens=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ-j__WeUx2Z"
      },
      "source": [
        "- Even if the **`max_tokens`** is set to 100, the model still didn't generate that many, as the query could be answered with a limited number of tokens.  \n",
        "\n",
        "- One of the reasons could be that the temperature is set to 0, making the model more deterministic and less creative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2oW34Ikmj3u"
      },
      "source": [
        "### Query 2: List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "3QqXzEjqmj3u",
        "outputId": "83bb448c-1a55-4b33-9ed8-2089cabd3712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"- Deep expertise: Apple's managers are expected to possess deep expertise that allows them to meaningfully engage in all the work being done within their individual functions. The assumption is that it's easier to train an expert to manage well than to train a manager to be an expert. At Apple, experts lead experts and this approach cascades down all levels of the organization.\\n- Immersion in the details: Leaders at Apple are expected to know the details of their organization three levels down for effective cross-functional decision-making at the highest levels. Managers attend decision-making meetings with the details at their disposal, and if not, the decision must either be made without the details or postponed. Apple's leaders pay extreme attention to the exact shape of products' rounded corners and demand extremely precise manufacturing tolerances to produce millions of products with continuous curves.\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
        "generate_rag_response(user_input_2, temperature=0.1, max_tokens=350)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"- Deep expertise: Apple's managers are expected to possess deep expertise that allows them to meaningfully engage in all the work being done within their individual functions. The assumption is that it's easier to train an expert to manage well than to train a manager to be an expert. At Apple, experts lead experts and this approach cascades down all levels of the organization.\\n- Immersion in the details: Leaders at Apple are expected to know the details of their organization three levels down for effective cross-functional decision-making at the highest levels. Managers attend decision-making meetings with the details at their disposal, and if not, the decision must either be made without the details or postponed. Apple's leaders pay extreme attention to the exact shape of products' rounded corners and demand extremely precise manufacturing tolerances to produce millions of products with continuous curves.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkUfmKNsWKbD"
      },
      "source": [
        "- If we compare it to the previous case, after increasing the **`max_tokens`**, we got the third characteristic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgwGYH8rmj3u"
      },
      "source": [
        "### Query 3: Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "bFrYiZnjmj3v",
        "outputId": "3b870c8f-23d2-40e8-8550-695b64b39d54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 145 prefix-match hit, remaining 1704 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1175.68 ms\n",
            "llama_perf_context_print: prompt eval time =  131397.12 ms /  1704 tokens (   77.11 ms per token,    12.97 tokens per second)\n",
            "llama_perf_context_print:        eval time =   11819.82 ms /    45 runs   (  262.66 ms per token,     3.81 tokens per second)\n",
            "llama_perf_context_print:       total time =  143233.20 ms /  1749 tokens\n",
            "llama_perf_context_print:    graphs reused =         42\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"I don't know. The article discusses Apple's functional organization and how it has contributed to the company's innovation success, but it does not provide specific examples of innovations that resulted from this approach.\""
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
        "generate_rag_response(user_input_3, top_p=0.98, top_k=20, max_tokens=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yRXlorfXayK"
      },
      "source": [
        "- Since the context provided doesn't help with the query, the model has responded correctly based on the prompt design.  \n",
        "\n",
        "- However, there is a chance that it might not be present in the top **`k`** context. Therefore, it is better to experiment with higher values of **`k`** and check."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyQrTipNfuBN"
      },
      "source": [
        "# Output Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbXMSxqa-65E"
      },
      "source": [
        "Let us now use the LLM-as-a-judge method to check the quality of the RAG system on two parameters - retrieval and generation. We illustrate this evaluation based on the answeres generated to the question from the previous section.\n",
        "\n",
        "- We are using the same Mistral model for evaluation, so basically here the llm is rating itself on how well he has performed in the task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuNYGRDE4HpJ"
      },
      "source": [
        "### Defining the Evaluation Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2dDxkZdyKSnh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "groundedness_rater_system_message = \"\"\"\n",
        "You are tasked with rating AI generated answers to questions posed by users.\n",
        "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
        "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
        "\n",
        "Evaluation criteria:\n",
        "The task is to judge the extent to which the metric is followed by the answer.\n",
        "1 - The metric is not followed at all\n",
        "2 - The metric is followed only to a limited extent\n",
        "3 - The metric is followed to a good extent\n",
        "4 - The metric is followed mostly\n",
        "5 - The metric is followed completely\n",
        "\n",
        "Metric:\n",
        "The answer should be derived only from the information presented in the context\n",
        "\n",
        "Instructions:\n",
        "1. First write down the steps that are needed to evaluate the answer as per the metric.\n",
        "2. Give a step-by-step explanation if the answer adheres to the metric considering the question and context as the input.\n",
        "3. Next, evaluate the extent to which the metric is followed.\n",
        "4. Use the previous information to rate the answer using the evaluaton criteria and assign a score.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "NIosu2Wk7OVs",
        "tags": []
      },
      "outputs": [],
      "source": [
        "relevance_rater_system_message = \"\"\"\n",
        "You are tasked with rating AI generated answers to questions posed by users.\n",
        "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
        "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
        "\n",
        "Evaluation criteria:\n",
        "The task is to judge the extent to which the metric is followed by the answer.\n",
        "1 - The metric is not followed at all\n",
        "2 - The metric is followed only to a limited extent\n",
        "3 - The metric is followed to a good extent\n",
        "4 - The metric is followed mostly\n",
        "5 - The metric is followed completely\n",
        "\n",
        "Metric:\n",
        "Relevance measures how well the answer addresses the main aspects of the question, based on the context.\n",
        "Consider whether all and only the important aspects are contained in the answer when evaluating relevance.\n",
        "\n",
        "Instructions:\n",
        "1. First write down the steps that are needed to evaluate the context as per the metric.\n",
        "2. Give a step-by-step explanation if the context adheres to the metric considering the question as the input.\n",
        "3. Next, evaluate the extent to which the metric is followed.\n",
        "4. Use the previous information to rate the context using the evaluaton criteria and assign a score.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "7boMupgh_Gux",
        "tags": []
      },
      "outputs": [],
      "source": [
        "user_message_template = \"\"\"\n",
        "###Question\n",
        "{question}\n",
        "\n",
        "###Context\n",
        "{context}\n",
        "\n",
        "###Answer\n",
        "{answer}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8XUDmew4Mzn"
      },
      "source": [
        "### Defining the Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "q9UVEOZbXYlh"
      },
      "outputs": [],
      "source": [
        "def generate_ground_relevance_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=3)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    prompt = f\"\"\"[INST]{qna_system_message}\\n\n",
        "                {'user'}: {qna_user_message_template.format(context=context_for_query, question=user_input)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response = llm(\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    answer =  response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    groundedness_prompt = f\"\"\"[INST]{groundedness_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    relevance_prompt = f\"\"\"[INST]{relevance_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response_1 = llm(\n",
        "            prompt=groundedness_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    response_2 = llm(\n",
        "            prompt=relevance_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    return response_1['choices'][0]['text'],response_2['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yr8azRRmxsg"
      },
      "source": [
        "### Query 1: Who are the authors of this article and who published this article ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5odsyrmGmxsh",
        "outputId": "e01a5c6d-36dd-4683-8595-547a3c0881c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Steps to evaluate the answer:\n",
            "1. Identify the key information in the context related to the question.\n",
            "2. Check if the authors and publisher mentioned in the context are included in the AI generated answer.\n",
            "3. Verify that the answer is derived only from the information presented in the context and not from any external sources.\n",
            "\n",
            "Explanation:\n",
            "The AI generated answer correctly identifies Morten T. Hansen and Joel M. Podolny as the authors of the article and Harvard Business Review as the publisher. This information is directly taken from the context, specifically the author bylines and the publication name mentioned in the text. Therefore, the answer is derived only from the information presented in the context and adheres to the metric.\n",
            "\n",
            "Evaluation:\n",
            "The metric is followed completely.\n",
            "\n",
            "Rating:\n",
            "Based on the evaluation criteria, I would rate the AI generated answer as a 5, indicating that the metric is followed completely.\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            " Steps to evaluate the context as per the relevance metric:\n",
            "1. Identify the main aspects of the question: In this case, the main aspects of the question are identifying the authors of the article and the publisher of the article.\n",
            "2. Determine if all and only the important aspects are contained in the context: The context provides the names of the authors (Morten T. Hansen and Joel M. Podolny) and the name of the publisher (Harvard Business Review). Therefore, the context adheres to the relevance metric as it contains all the necessary information to answer the question.\n",
            "3. Evaluate the extent to which the metric is followed: The metric is followed completely as the context provides all the required information to answer the question.\n",
            "4. Assign a score based on the evaluation criteria: Since the metric is followed completely, the score would be 5.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=350)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print('-'*200)\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 467 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1175.68 ms\n",
            "llama_perf_context_print: prompt eval time =   31668.07 ms /   467 tokens (   67.81 ms per token,    14.75 tokens per second)\n",
            "llama_perf_context_print:        eval time =    7134.50 ms /    29 runs   (  246.02 ms per token,     4.06 tokens per second)\n",
            "llama_perf_context_print:       total time =   38812.57 ms /   496 tokens\n",
            "llama_perf_context_print:    graphs reused =         27\n",
            "Llama.generate: 7 prefix-match hit, remaining 616 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1175.68 ms\n",
            "llama_perf_context_print: prompt eval time =   46055.63 ms /   616 tokens (   74.77 ms per token,    13.38 tokens per second)\n",
            "llama_perf_context_print:        eval time =   42632.92 ms /   172 runs   (  247.87 ms per token,     4.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   88766.82 ms /   788 tokens\n",
            "llama_perf_context_print:    graphs reused =        166\n",
            "Llama.generate: 158 prefix-match hit, remaining 492 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1175.68 ms\n",
            "llama_perf_context_print: prompt eval time =   39018.99 ms /   492 tokens (   79.31 ms per token,    12.61 tokens per second)\n",
            "llama_perf_context_print:        eval time =   42507.45 ms /   171 runs   (  248.58 ms per token,     4.02 tokens per second)\n",
            "llama_perf_context_print:       total time =   81603.27 ms /   663 tokens\n",
            "llama_perf_context_print:    graphs reused =        165\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Steps to evaluate the answer:\n",
            "1. Identify the key information in the context related to the question.\n",
            "2. Check if the answer is derived only from the information in the context.\n",
            "3. Compare the answer with the information in the context to ensure accuracy.\n",
            "\n",
            "Explanation:\n",
            "The question asks for the authors of the article and the publisher. The context clearly states the names of the authors (Joel M. Podolny and Morten T. Hansen) and the publisher (Harvard Business Review). The AI generated answer matches the information in the context and is accurate.\n",
            "\n",
            "Evaluation:\n",
            "The metric is followed completely as the answer is derived only from the information presented in the context.\n",
            "\n",
            "Rating:\n",
            "Based on the evaluation criteria, the answer would receive a score of 5.\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            " Steps to evaluate the context as per the relevance metric:\n",
            "1. Identify the main aspects of the question: In this case, the main aspects of the question are identifying the authors of the article and the publisher of the article.\n",
            "2. Determine if the context contains all and only the important aspects: In this context, the authors' names (Joel M. Podolny and Morten T. Hansen) and the publisher (Harvard Business Review) are explicitly stated. Therefore, the context adheres to the relevance metric.\n",
            "\n",
            "The context follows the relevance metric to a great extent since it contains all the essential information needed to answer the question.\n",
            "\n",
            "Rating:\n",
            "Based on the evaluation criteria, the context would receive a score of 5 since it follows the relevance metric completely.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=350)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print('-'*200)\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgJI4DOdGHx0"
      },
      "source": [
        "- It got a perfect score because the response is both grounded in the context and relevant to the query.  \n",
        "- This means that both the retrieval and augmentation parts are good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDH6Va3Bmxsh"
      },
      "source": [
        "### Query 2: List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p7Q16kTmxsh",
        "outputId": "028a0b6c-5490-49ab-eb11-0ef4741146c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Steps to evaluate the answer:\n",
            "1. Identify the three leadership characteristics mentioned in the context.\n",
            "2. Check if each bullet point in the answer matches one of the leadership characteristics.\n",
            "3. Verify that the explanation under each bullet point is derived from the information presented in the context.\n",
            "\n",
            "The answer adheres to the metric considering the question and context as the input:\n",
            "\n",
            "* Deep expertise: The context states that Apple's managers are expected to possess deep expertise in their individual functions, and the organization is structured such that experts lead other experts. This information is used to form the first bullet point in the answer.\n",
            "  + Experts lead experts: This explanation is directly taken from the context.\n",
            "  + Cascades down all levels: The context states that this approach cascades down through all areas of the organization, which is explained in the second line under this bullet point.\n",
            "* Immersion in the details: The context states that Apple's leaders are expected to have an extreme attention to detail and that this immersion in the details is essential for effective cross-functional decision-making at the highest levels. This information is used to form the second bullet point in the answer.\n",
            "  + Essential for speedy and effective decision-making: The context states that leaders who know the details of their organization three levels down can make informed decisions quickly and effectively, which is explained in the first line under this bullet point.\n",
            "  + Central at the leadership level: The context states that Apple's senior leaders pay extreme attention to the details, which is directly stated in the second line under this bullet point.\n",
            "\n",
            "The metric is followed completely.\n",
            "\n",
            "Rating: 5 (The metric is followed completely)\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            " Steps to evaluate context as per relevance metric:\n",
            "1. Identify the main aspects of the question: In this case, the question asks for three leadership characteristics at Apple and an explanation of each one under two lines.\n",
            "2. Determine if the context provides information on the main aspects: The context discusses Apple's functional organization and the leadership model underlying it, specifically mentioning the three leadership characteristics: deep expertise and immersion in the details.\n",
            "3. Check if the context explains each characteristic: The context not only mentions the characteristics but also provides an explanation for each one. For deep expertise, it explains how experts lead experts and how this approach cascades down through all levels of the organization. For immersion in the details, it discusses how leaders pay extreme attention to the details and how this is essential for effective decision-making at the highest levels.\n",
            "\n",
            "The context adheres to the relevance metric as it addresses all the main aspects of the question by providing information on the three leadership characteristics and explaining each one under two lines based on the provided context.\n",
            "\n",
            "Rating:\n",
            "5 - The metric is followed completely.\n"
          ]
        }
      ],
      "source": [
        "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
        "ground,rel = generate_ground_relevance_response(user_input_2,max_tokens=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xFOz3gLX0pE",
        "outputId": "7ee66686-4780-4c1d-b6c5-ae0f6172d1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(' Steps to evaluate the answer:\\n'\n",
            " '1. Identify the key information in the context related to the question.\\n'\n",
            " '2. Check if the answer is derived only from the information in the context.\\n'\n",
            " '3. Compare the answer with the information in the context to ensure accuracy.\\n'\n",
            " '\\n'\n",
            " 'Explanation:\\n'\n",
            " 'The question asks for the authors of the article and the publisher. The context clearly states the names of the authors (Joel M. Podolny and '\n",
            " 'Morten T. Hansen) and the publisher (Harvard Business Review). The AI generated answer matches the information in the context and is accurate.\\n'\n",
            " '\\n'\n",
            " 'Evaluation:\\n'\n",
            " 'The metric is followed completely as the answer is derived only from the information presented in the context.\\n'\n",
            " '\\n'\n",
            " 'Rating:\\n'\n",
            " 'Based on the evaluation criteria, the answer would receive a score of 5.')\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "(' Steps to evaluate the context as per the relevance metric:\\n'\n",
            " '1. Identify the main aspects of the question: In this case, the main aspects of the question are identifying the authors of the article and the '\n",
            " 'publisher of the article.\\n'\n",
            " \"2. Determine if the context contains all and only the important aspects: In this context, the authors' names (Joel M. Podolny and Morten T. \"\n",
            " 'Hansen) and the publisher (Harvard Business Review) are explicitly stated. Therefore, the context adheres to the relevance metric.\\n'\n",
            " '\\n'\n",
            " 'The context follows the relevance metric to a great extent since it contains all the essential information needed to answer the question.\\n'\n",
            " '\\n'\n",
            " 'Rating:\\n'\n",
            " 'Based on the evaluation criteria, the context would receive a score of 5 since it follows the relevance metric completely.')\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pprint.pp(ground, width = 150)\n",
        "print('-'*200)\n",
        "pprint.pp(rel, width = 150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpcn0QLOHLYW"
      },
      "source": [
        "- The groundedness score is 5 since the response is derived solely from the context.  \n",
        "\n",
        "- Regarding relevance, the score is 4 (the metric is mostly followed). However, it is not very clear why this rating was given.  \n",
        "\n",
        "- One solution is to modify the relevance prompt to instruct the model to provide reasons for any point deductions or increase the max_tokens (assuming the output has been truncated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6xAHrl9mxsh"
      },
      "source": [
        "### Query 3: Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaMjr9Ocmxsi",
        "outputId": "43a05842-ca91-4b49-e3dc-89d8ef9f37eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(' Steps to evaluate the answer:\\n'\n",
            " \"1. Identify the specific examples mentioned in the context related to Apple's approach to leadership and successful \"\n",
            " 'innovations.\\n'\n",
            " '2. Determine if the AI generated answer is derived only from the information presented in the context.\\n'\n",
            " '\\n'\n",
            " 'Evaluation:\\n'\n",
            " \"The AI generated answer adheres to the metric as it mentions the specific example of the iPhone's development under \"\n",
            " \"Apple's functional organization and the evolution of the leadership approach that contributed to its success. The \"\n",
            " 'answer is directly derived from the context provided.\\n'\n",
            " '\\n'\n",
            " 'Rating:\\n'\n",
            " 'Based on the evaluation criteria, I would rate this answer as a 5 - The metric is followed completely. The AI '\n",
            " 'generated answer is fully derived from the information presented in the context and provides a specific example of '\n",
            " \"how Apple's approach to leadership has led to successful innovations.\")\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "(' Steps to evaluate context as per the metric:\\n'\n",
            " \"1. Identify the main aspects of the question which are specific examples from the article where Apple's approach to \"\n",
            " 'leadership has led to successful innovations.\\n'\n",
            " \"2. Read through the context to understand how Apple's organizational design and leadership model have contributed to \"\n",
            " 'their innovation success.\\n'\n",
            " \"3. Look for instances in the context that provide specific examples of successful innovations and how Apple's \"\n",
            " 'functional organization and leadership approach played a role in their development.\\n'\n",
            " '\\n'\n",
            " 'The context adheres to the metric considering the question as input:\\n'\n",
            " \"1. The context provides an explanation of Apple's organizational design and leadership model, which is directly \"\n",
            " 'related to the question about specific examples of successful innovations.\\n'\n",
            " \"2. The context includes several instances where Apple's functional organization and leadership approach have led to \"\n",
            " 'successful innovations, such as the development of the iPhone.\\n'\n",
            " '3. The context also discusses how Apple has evolved its leadership approach to address the challenges posed by '\n",
            " 'organizational growth and the need for senior leaders to oversee more details and new areas of responsibility '\n",
            " 'outside their core expertise.\\n'\n",
            " '\\n'\n",
            " 'The metric is followed mostly:\\n'\n",
            " '1. The context provides several specific examples of successful innovations at Apple and explains how their '\n",
            " 'functional organization and leadership approach contributed to their development.\\n'\n",
            " '2. The context also discusses how Apple has evolved its leadership approach to address the challenges posed by '\n",
            " 'organizational growth, demonstrating a commitment to continuous improvement.\\n'\n",
            " '3. However, the context could be improved by providing more specific examples beyond the iPhone to further '\n",
            " \"illustrate the effectiveness of Apple's functional organization and leadership model in driving innovation.\")\n"
          ]
        }
      ],
      "source": [
        "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input_3,max_tokens=500)\n",
        "\n",
        "pprint.pp(ground,width = 120)\n",
        "print('-'*200)\n",
        "pprint.pp(rel, width = 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duJHMNwbIAVl"
      },
      "source": [
        "- For relevance, the response includes both the score and the reason for the point deduction.  \n",
        "\n",
        "- For groundedness, it is unclear why one point was deducted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMCN2_H204M_"
      },
      "source": [
        "# Business Insights and Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i8pILGhmWzf"
      },
      "source": [
        "- Vector database creation time increases with the number of pages in the PDF document.\n",
        "- Retrieval parameter **`k`** is critical as the answer can be spread across multiple contexts.\n",
        "- **`chunk_overlap`** ensures coherence, especially when context spans across chunks.\n",
        "- **`max_tokens`** depends on query complexity; higher values yield detailed responses, while simple queries result in concise outputs despite large token limits due to prompt design and zero **`temperature`**.\n",
        "- Refine prompt design and temperature settings to control response length and creativity.\n",
        "- Continuously adjust RAG parameters based on specific use cases for optimal performance.\n",
        "- Prioritize groundedness and relevance in evaluations to ensure reliable and contextually accurate outputs.\n",
        "- Establish a feedback loop to fine-tune parameters, improving performance for diverse query types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5krdyzboO--"
      },
      "source": [
        "<font size=4 color='orange'>Learn more at www.sunitechai.com</font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QDw8zXuq6B0F",
        "TggYyQPL6B0G",
        "x2oW34Ikmj3u",
        "jgwGYH8rmj3u",
        "yyQrTipNfuBN",
        "tuNYGRDE4HpJ",
        "e8XUDmew4Mzn",
        "8Yr8azRRmxsg",
        "GDH6Va3Bmxsh",
        "J6xAHrl9mxsh"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c76b11163d46e2acc9901306324d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0328be5108064b438d127d1f3f89d706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d795f539a04bfb9713591309e85e59",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4dfe2b09306405cb7acba6c80a85d76",
            "value": 125
          }
        },
        "071244468c4d4a61b4a8461255981b22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0784683c24e34abdac58504f3b23c060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284dd6c6fce048db8fc3cdec0e4b3a27",
            "placeholder": "​",
            "style": "IPY_MODEL_48f9195ed6ae44efab2f82d3ab5e9014",
            "value": "README.md: "
          }
        },
        "0b4f23a059f94251ae66a8bcfe098197": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5f3adb4f1f4b5f8383297ef1b123f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c67197e8a604a04843f98f6ef59e9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1042df6a4fe54e228d0fe86708b96b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104e907c5ac847558e30621f23bfff37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10c5f13ff2e14a1bb4fc069b3d18493b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11e70001fa8c449f978ce22afd48ea15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "122ea0a1f2e74000b50dabd4e92a1fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb7bbca2fecd456c82a14913b8b2ea9c",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4be290e6fe4f48e5befc6312824b7000",
            "value": 385
          }
        },
        "124174e5be1d487196b6c7517020af1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "139588481a3f47bfa1adf31dadb19c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6642f20de27d47af8ebc0c17f74301b9",
              "IPY_MODEL_27c14a4b98224ed2a053297d076cd904",
              "IPY_MODEL_fcaa7acf5710412d99a44f0a2977102d"
            ],
            "layout": "IPY_MODEL_55815983f2154440b92a349b6636a723"
          }
        },
        "1517054cbae045afbcac928a5b25aba2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a45aba0ef3143199da27defc7906351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b3f9d6332914f659b2418f5c7872ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_258c4a71fea344b995738411f1b6bbef",
            "placeholder": "​",
            "style": "IPY_MODEL_fe1f092ee0ac4f3faff7490a00ac06b6",
            "value": " 670M/670M [00:10&lt;00:00, 39.3MB/s]"
          }
        },
        "229b642ab45248a9b5d8191c9c78b4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258c4a71fea344b995738411f1b6bbef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c14a4b98224ed2a053297d076cd904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb3a1dec16c4f78b3f67b7b7d8ec44e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c57b67ace2c4ca2afd4547f5bbb22f1",
            "value": 1
          }
        },
        "284dd6c6fce048db8fc3cdec0e4b3a27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28515cdb6f9049219fb72164b5da6fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1568b7167c4aa0a5f40ead24a550aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ade54dce7a34ede9af2ce35a8e6d6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908f92f5c8da491395eb7fd33bca91b4",
            "placeholder": "​",
            "style": "IPY_MODEL_b04be5327ba542b69d31f62264c3b691",
            "value": "model.safetensors: 100%"
          }
        },
        "30880cb3eda9491791e6137b32eb091d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a960414a0749c7aa1b2599a36570bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349469e5ef7b4f60adb9721de69286c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63c6050768c3443ca009d64398db9c32",
              "IPY_MODEL_3c1eac8560684f5dbcae5ba0ba2fb344",
              "IPY_MODEL_e9a171c3dc6642428845867f22b5e20c"
            ],
            "layout": "IPY_MODEL_28515cdb6f9049219fb72164b5da6fa9"
          }
        },
        "37151f50c7754f93b30b8dd83aa5883f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37d513df0c4348e68ed810a56fc7be45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3a562e80d74d4a66a19b5739e36902ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68b34f08c1b5485db6b361e32e1e9cc2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e306e4817e0a447faa76dd87cfbbf90c",
            "value": 1
          }
        },
        "3bc914a6c4104d8cae5c993a78bef7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87f27fc9a4ca40448d987c15baefad18",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d668ec7db82d4a77bbbb2ae786116ee9",
            "value": 619
          }
        },
        "3c1eac8560684f5dbcae5ba0ba2fb344": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3918214ca74f8484ce8a90385b4ded",
            "max": 342,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_124174e5be1d487196b6c7517020af1a",
            "value": 342
          }
        },
        "3cde06a1d3924128ad82b14c14b1800e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "474c5e3f171b468a91ca085c1ed42656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad33b6e9e48f479483ddf3dff54b0367",
              "IPY_MODEL_3bc914a6c4104d8cae5c993a78bef7a3",
              "IPY_MODEL_59951bc8ff534bb78e2801f03fafcce5"
            ],
            "layout": "IPY_MODEL_b5a8e931224442b682516a7f4f5530f0"
          }
        },
        "4794419dc53a41ceb53ef398076edbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35efbc94c194eafb35dcf4236847de6",
            "placeholder": "​",
            "style": "IPY_MODEL_7b28e13fb0df4cf28884af2c51c06df1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "48f9195ed6ae44efab2f82d3ab5e9014": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5b7532a3cd46b389a9ba51bb877351": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be290e6fe4f48e5befc6312824b7000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d2c37136a054141bd4a9601388c5c18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fecc2a4edd545dca5bc97d6512aaf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ffa9aa99659483faf7a03a8a5388471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55815983f2154440b92a349b6636a723": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558ed4e440934269875b734f0203d2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92760f407854286b330e212cd716c7e",
            "placeholder": "​",
            "style": "IPY_MODEL_ba697a1a7c0845cd96df84e982b5d1c9",
            "value": "vocab.txt: "
          }
        },
        "59951bc8ff534bb78e2801f03fafcce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ff6a483d50e48b78a693a02bfeca462",
            "placeholder": "​",
            "style": "IPY_MODEL_e27a06c42bd2470f80cc7a33a0db6856",
            "value": " 619/619 [00:00&lt;00:00, 70.1kB/s]"
          }
        },
        "5ba7bc5cbfad470f8b6cd2612bf1dfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_071244468c4d4a61b4a8461255981b22",
            "placeholder": "​",
            "style": "IPY_MODEL_11e70001fa8c449f978ce22afd48ea15",
            "value": "modules.json: 100%"
          }
        },
        "5c687094f71442348bce74578dd650bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e995705a3ca4a1fbe85f7990e12498d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60bbb98320ee4ddbbe806180d6b24397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e3f938ae9148dabd5e9c61c213dfea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63c6050768c3443ca009d64398db9c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e3f938ae9148dabd5e9c61c213dfea",
            "placeholder": "​",
            "style": "IPY_MODEL_37151f50c7754f93b30b8dd83aa5883f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6642f20de27d47af8ebc0c17f74301b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b29a3591b44946b1568c5ba9ad65a6",
            "placeholder": "​",
            "style": "IPY_MODEL_0c67197e8a604a04843f98f6ef59e9c8",
            "value": "tokenizer.json: "
          }
        },
        "68b34f08c1b5485db6b361e32e1e9cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "69bb5ba5267148bd970f6c1e812f4d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfcc24009c044c3384c9edb2351f9104",
            "max": 670332568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9430a3d0b4d5446e885698e5beef8e41",
            "value": 670332568
          }
        },
        "6bc31622383c46709642b86fc8a66333": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a960414a0749c7aa1b2599a36570bd",
            "placeholder": "​",
            "style": "IPY_MODEL_c2a00c17f51346388470582afd44f912",
            "value": "mistral-7b-instruct-v0.2.Q6_K.gguf: 100%"
          }
        },
        "6c1fbc078d2b44438f269b171840545a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6db55b11834d89aa72a9eed0f8641a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72b1b99b6ae5487f8e7ca6d191dceb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4794419dc53a41ceb53ef398076edbb0",
              "IPY_MODEL_0328be5108064b438d127d1f3f89d706",
              "IPY_MODEL_76f6ab8e8b5a4f0cafa89a5a5276f4b1"
            ],
            "layout": "IPY_MODEL_4a5b7532a3cd46b389a9ba51bb877351"
          }
        },
        "751c62f11e6b429f87a9c84f8219958e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bc31622383c46709642b86fc8a66333",
              "IPY_MODEL_bdb561482db54e8bb2c162e9e76a14a6",
              "IPY_MODEL_8eecbc74dcd24f2fb0477ffbdc9fa70e"
            ],
            "layout": "IPY_MODEL_8aacb1c7e6b4414b86fb274fcc38f97f"
          }
        },
        "76e02cfb13444e84b607d10fc6d32599": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f6ab8e8b5a4f0cafa89a5a5276f4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b4f23a059f94251ae66a8bcfe098197",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8cd6eac84c4911af2de242d14f2f40",
            "value": " 125/125 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "7b28e13fb0df4cf28884af2c51c06df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b3918214ca74f8484ce8a90385b4ded": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc1fc91c3b24078a41204bc6c95b62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30880cb3eda9491791e6137b32eb091d",
            "placeholder": "​",
            "style": "IPY_MODEL_4fecc2a4edd545dca5bc97d6512aaf9f",
            "value": "config.json: 100%"
          }
        },
        "7dd581f9206d43b6b0fd5d841df52b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ade54dce7a34ede9af2ce35a8e6d6cc",
              "IPY_MODEL_69bb5ba5267148bd970f6c1e812f4d53",
              "IPY_MODEL_1b3f9d6332914f659b2418f5c7872ff9"
            ],
            "layout": "IPY_MODEL_fc9d284f48ea41e2a5118170b495be63"
          }
        },
        "7e6a681a18774b1cb89e4c14724ae0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85813d47137f430e8f43427746ddf447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94a6c69cbb5845eea30b5065cc95e5d3",
            "placeholder": "​",
            "style": "IPY_MODEL_60bbb98320ee4ddbbe806180d6b24397",
            "value": " 191/191 [00:00&lt;00:00, 16.1kB/s]"
          }
        },
        "87f27fc9a4ca40448d987c15baefad18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aacb1c7e6b4414b86fb274fcc38f97f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8dd0f254874f448ceb0691e5b24e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229b642ab45248a9b5d8191c9c78b4b0",
            "max": 57,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6bd713259ca4da380bc2bcb964b4bd0",
            "value": 57
          }
        },
        "8d1ec7eedefb459bb7153bfe0a3c50c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eecbc74dcd24f2fb0477ffbdc9fa70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa357c918904594b3304baa4ad2abbe",
            "placeholder": "​",
            "style": "IPY_MODEL_e553c5dc52bb42a6b22384f2d7b92056",
            "value": " 5.94G/5.94G [00:42&lt;00:00, 101MB/s]"
          }
        },
        "908f92f5c8da491395eb7fd33bca91b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "923865a7e1114b8d9440f1777c76305f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9309f541ecc949dd8321175014e2432b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d513df0c4348e68ed810a56fc7be45",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af471519a79846c1b9a35acd0ed0f7e1",
            "value": 1
          }
        },
        "9430a3d0b4d5446e885698e5beef8e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94a6c69cbb5845eea30b5065cc95e5d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954e36502fb344bfa5d925c458f7cabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d1ec7eedefb459bb7153bfe0a3c50c5",
            "placeholder": "​",
            "style": "IPY_MODEL_3cde06a1d3924128ad82b14c14b1800e",
            "value": " 232k/? [00:00&lt;00:00, 12.2MB/s]"
          }
        },
        "96291c263adb42c4a2ddeef96eb9578a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968d53fd1cc9483dbe5d3c96eeb9c54b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c57b67ace2c4ca2afd4547f5bbb22f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ff6a483d50e48b78a693a02bfeca462": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b0165de9bb45e68c96c77ff0aa543b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104e907c5ac847558e30621f23bfff37",
            "placeholder": "​",
            "style": "IPY_MODEL_6e6db55b11834d89aa72a9eed0f8641a",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "a2d795f539a04bfb9713591309e85e59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a565a00855fc49bdad8e9b5bf1b688f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac08a70b191948f0b32b9aa73276e7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8cd6eac84c4911af2de242d14f2f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad33b6e9e48f479483ddf3dff54b0367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96291c263adb42c4a2ddeef96eb9578a",
            "placeholder": "​",
            "style": "IPY_MODEL_10c5f13ff2e14a1bb4fc069b3d18493b",
            "value": "config.json: 100%"
          }
        },
        "af471519a79846c1b9a35acd0ed0f7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b04be5327ba542b69d31f62264c3b691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5a8e931224442b682516a7f4f5530f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba697a1a7c0845cd96df84e982b5d1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7f7d5709f04c369d876038fdafb5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1042df6a4fe54e228d0fe86708b96b41",
            "max": 191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cef8b411414b4e00a179d9e8c9c28914",
            "value": 191
          }
        },
        "bdb3a1dec16c4f78b3f67b7b7d8ec44e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bdb561482db54e8bb2c162e9e76a14a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_968d53fd1cc9483dbe5d3c96eeb9c54b",
            "max": 5942065440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ffa9aa99659483faf7a03a8a5388471",
            "value": 5942065440
          }
        },
        "bfa357c918904594b3304baa4ad2abbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a00c17f51346388470582afd44f912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c336e07f97614cf58d96ef4dba0b532f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1517054cbae045afbcac928a5b25aba2",
            "placeholder": "​",
            "style": "IPY_MODEL_1a45aba0ef3143199da27defc7906351",
            "value": " 385/385 [00:00&lt;00:00, 35.8kB/s]"
          }
        },
        "c35efbc94c194eafb35dcf4236847de6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6bd713259ca4da380bc2bcb964b4bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8c846d7ba9340a68fcbcf2c3c1c16bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2b0165de9bb45e68c96c77ff0aa543b",
              "IPY_MODEL_8b8dd0f254874f448ceb0691e5b24e13",
              "IPY_MODEL_ede2d0657d7741a9a856e3ccd075d8e0"
            ],
            "layout": "IPY_MODEL_5e995705a3ca4a1fbe85f7990e12498d"
          }
        },
        "c92760f407854286b330e212cd716c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef8b411414b4e00a179d9e8c9c28914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfcc24009c044c3384c9edb2351f9104": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d668ec7db82d4a77bbbb2ae786116ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8b29a3591b44946b1568c5ba9ad65a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4844ce7f7a491aa20a278771bb6a53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4d4e20a9f8440bb706b348cbdf94e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cc1fc91c3b24078a41204bc6c95b62c",
              "IPY_MODEL_bd7f7d5709f04c369d876038fdafb5f3",
              "IPY_MODEL_85813d47137f430e8f43427746ddf447"
            ],
            "layout": "IPY_MODEL_76e02cfb13444e84b607d10fc6d32599"
          }
        },
        "e27a06c42bd2470f80cc7a33a0db6856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e306e4817e0a447faa76dd87cfbbf90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e553c5dc52bb42a6b22384f2d7b92056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9a171c3dc6642428845867f22b5e20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a1568b7167c4aa0a5f40ead24a550aa",
            "placeholder": "​",
            "style": "IPY_MODEL_7e6a681a18774b1cb89e4c14724ae0aa",
            "value": " 342/342 [00:00&lt;00:00, 22.1kB/s]"
          }
        },
        "ede2d0657d7741a9a856e3ccd075d8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5f3adb4f1f4b5f8383297ef1b123f2",
            "placeholder": "​",
            "style": "IPY_MODEL_00c76b11163d46e2acc9901306324d69",
            "value": " 57.0/57.0 [00:00&lt;00:00, 6.58kB/s]"
          }
        },
        "f19c50b81c824ce19c04e2627575c548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0784683c24e34abdac58504f3b23c060",
              "IPY_MODEL_9309f541ecc949dd8321175014e2432b",
              "IPY_MODEL_f2e17e82dc6d46b09f7e0bb38b91d3fc"
            ],
            "layout": "IPY_MODEL_6c1fbc078d2b44438f269b171840545a"
          }
        },
        "f2e17e82dc6d46b09f7e0bb38b91d3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4844ce7f7a491aa20a278771bb6a53",
            "placeholder": "​",
            "style": "IPY_MODEL_5c687094f71442348bce74578dd650bf",
            "value": " 67.9k/? [00:00&lt;00:00, 4.20MB/s]"
          }
        },
        "f4dfe2b09306405cb7acba6c80a85d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8ad6a4bf0824915a2d0cdd1f334ad02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_558ed4e440934269875b734f0203d2e3",
              "IPY_MODEL_3a562e80d74d4a66a19b5739e36902ee",
              "IPY_MODEL_954e36502fb344bfa5d925c458f7cabd"
            ],
            "layout": "IPY_MODEL_ac08a70b191948f0b32b9aa73276e7ef"
          }
        },
        "fb7bbca2fecd456c82a14913b8b2ea9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9d284f48ea41e2a5118170b495be63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcaa7acf5710412d99a44f0a2977102d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d2c37136a054141bd4a9601388c5c18",
            "placeholder": "​",
            "style": "IPY_MODEL_a565a00855fc49bdad8e9b5bf1b688f8",
            "value": " 712k/? [00:00&lt;00:00, 38.6MB/s]"
          }
        },
        "fd9e8ac5eda94d349f2b369af9b8e0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ba7bc5cbfad470f8b6cd2612bf1dfb5",
              "IPY_MODEL_122ea0a1f2e74000b50dabd4e92a1fee",
              "IPY_MODEL_c336e07f97614cf58d96ef4dba0b532f"
            ],
            "layout": "IPY_MODEL_923865a7e1114b8d9440f1777c76305f"
          }
        },
        "fe1f092ee0ac4f3faff7490a00ac06b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
